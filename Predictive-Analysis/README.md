

# TOPIC 1: Supervised Learning (k-Nearest Neighbors Algorithm)



Supervised learning is a fundamental approach in predictive analytics, where a model learns from labeled data to make predictions. In this topic, we will focus on the k-Nearest Neighbors (kNN) algorithm, a simple yet powerful classification technique.

### Learning Materials:

## Lecture 01 Slides : Supervised Learning and the kNN Algorithm

Code Examples:

- [kNN Algorithm Using the sklearn Library](Topic-1/01_kNN_sklearn.ipynb): For hands-on implementation, use this notebook with sklearn to easily apply the kNN algorithm. (Recommended for Assignment 1)
- [kNN Algorithm from Scratch](https://deepnote.com/app/ndungu/Implementing-KNN-Algorithm-on-the-Iris-Dataset-e7c16493-500c-4248-be54-9389de603f16) (For Practice Only): Understand the inner workings of the kNN algorithm with a Python implementation built from scratch. (Note: This is for practice and not required for Assignment 1).
- [Euclidean Distance Notebook](Topic-1/Euclidean_Distance.ipynb)

#### Cross Validation:
Cross-validation is essential to ensure your model generalizes well to new data. Weâ€™ll use k-fold cross-validation with the kNN algorithm to assess performance.

- [kNN with k-Fold Cross Validation](Topic-1/02_kNN_kfold.ipynb) (Notebook): Explore how to implement k-fold cross-validation using sklearn and kNN to improve model reliability.

- [Explanation of k-Fold Cross Validation](https://machinelearningmastery.com/k-fold-cross-validation/) (External Link): Review this linked article for an in-depth explanation of k-fold cross-validation.

#### Additional Resources: Here are some resources to deepen your understanding about the field Data Science:

- What is Data Science: Understand the fundamentals of data science.

- Data Science vs. Machine Learning: Discover the differences between data science and machine learning and how they complement each other.


# TOPIC 2: Support Vector Machines (SVM)
Support Vector Machines (SVM) are powerful supervised learning algorithms primarily used for classification tasks, though they can also be applied to regression. SVM is highly effective in cases where the decision boundary is complex.

#### Learning Materials:

[Lecture Slides on Support Vector Machines (SVM)](https://docs.google.com/presentation/d/1wrXwPpTQ6099bhwubPyz5M9W705UyFvCyBI3XJG2B2s/edit#slide=id.g30f52f0f268_2_235):
An in-depth look at the theory and application of SVM, covering its foundation, types of kernels, and practical applications in classification.

#### Code Examples:

- [SVM Implementation with sklearn](Topic-2/01_SVM_Basics.ipynb) (Notebook): Practice building an SVM model using sklearn. This notebook will guide you through the basics of SVM implementation.

- [SVM with Different Kernels](Topic-2/02_Polynomial_SVM_Moons.ipynb) (Notebook): Explore the impact of different kernel functions (linear, polynomial) on SVM performance.

#### Additional Resources:

- scikit-learn SVM Documentation: [Comprehensive guide to SVMs in scikit-learn](https://scikit-learn.org/stable/modules/svm.html), covering implementation, kernels, and tuning options.
- Book: [Hands-On Machine Learning with Scikit-Learn - Chapter 5](https://hamk.finna.fi/PrimoRecord/pci.cdi_askewsholts_vlebooks_9781492032618?sid=4863288493)
- [Code Notebook from Book](Topic-2/Feature_Selection.ipynb)
